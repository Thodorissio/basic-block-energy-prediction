{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import embedder\n",
    "import os\n",
    "import itertools\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity of embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_block_a = [\n",
    "    \"mov rbp rdi\",\n",
    "    \"mov ebx 0x1\",\n",
    "    \"mov rdx rbx\",\n",
    "    \"call memcpy\",\n",
    "    \"mov [ rcx + rbx ] 0x0\",\n",
    "    \"mov rcx rax\",\n",
    "    \"mov [ rax ] 0x2e\"\n",
    "]\n",
    "\n",
    "basic_block_b = [\n",
    "    \"push    rbp\",\n",
    "    \"mov     rbp, rsp\",\n",
    "    \"mov     DWORD PTR [rbp-4], 1\",\n",
    "    \"mov     DWORD PTR [rbp-8], 2\",\n",
    "    \"mov     eax, DWORD PTR [rbp-8]\",\n",
    "    \"add     DWORD PTR [rbp-4], eax\",\n",
    "    \"mov     eax, DWORD PTR [rbp-4]\",\n",
    "    \"add     DWORD PTR [rbp-8], eax\",\n",
    "    \"mov     eax, 0\",\n",
    "    \"pop     rbp\"\n",
    "]\n",
    "\n",
    "basic_block_c = [\n",
    "    \"push    rbp\",\n",
    "    \"mov     rbp, rsp\",\n",
    "    \"mov     DWORD PTR [rbp-4], 35\",\n",
    "    \"mov     DWORD PTR [rbp-8], 7\",\n",
    "    \"mov     eax, DWORD PTR [rbp-8]\",\n",
    "    \"add     DWORD PTR [rbp-4], eax\",\n",
    "    \"sal     DWORD PTR [rbp-8]\",\n",
    "    \"mov     eax, 0\",\n",
    "    \"pop     rbp\",\n",
    "    \"ret\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Vocab C:/Users/thodo/Documents/σχολη/diplomatiki/PalmTree/pre-trained_model/palmtree/vocab\n",
      "Vocab Size:  6631\n",
      "Loading Vocab C:/Users/thodo/Documents/σχολη/diplomatiki/PalmTree/pre-trained_model/palmtree/vocab\n",
      "Vocab Size:  6631\n",
      "Loading Vocab C:/Users/thodo/Documents/σχολη/diplomatiki/PalmTree/pre-trained_model/palmtree/vocab\n",
      "Vocab Size:  6631\n"
     ]
    }
   ],
   "source": [
    "embedding_a = embedder.encode(basic_block_a)\n",
    "embedding_b = embedder.encode(basic_block_b)\n",
    "embedding_c = embedder.encode(basic_block_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding size: 128\n"
     ]
    }
   ],
   "source": [
    "print(f\"Embedding size: {embedding_a[0].shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity between block a and block b: [[ 0.49150878  0.4220034   0.27718437  0.3487818   0.27718437  0.25324777\n",
      "   0.27718437  0.25324777  0.38834393  0.28084812]\n",
      " [ 0.32998472  0.15667099  0.12095444  0.3624119   0.12095444  0.2647658\n",
      "   0.12095444  0.2647658   0.3404262   0.1270635 ]\n",
      " [ 0.23312676  0.54436576  0.44745097  0.4408702   0.44745097  0.373129\n",
      "   0.44745097  0.373129    0.53880054 -0.0146948 ]\n",
      " [ 0.22675245  0.39233464  0.33453208  0.38435885  0.33453208  0.3280302\n",
      "   0.33453208  0.3280302   0.42625856  0.03198011]\n",
      " [ 0.43719926  0.36515874  0.34633172  0.47983998  0.34633172  0.2825651\n",
      "   0.34633172  0.2825651   0.40553728  0.18389228]\n",
      " [ 0.32912382  0.3605289   0.35443223  0.46263847  0.35443223  0.32784587\n",
      "   0.35443223  0.32784587  0.5312316   0.19034882]\n",
      " [ 0.34697768  0.1704338   0.30426726  0.3980337   0.30426726  0.03928765\n",
      "   0.30426726  0.03928765  0.27795523  0.39345598]]\n"
     ]
    }
   ],
   "source": [
    "cosine_simil = cosine_similarity(embedding_a, embedding_b)\n",
    "print(f'Cosine Similarity between block a and block b: {cosine_simil}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very similar blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity between block a and block b: [[0.99999994 0.16156007 0.20755175 0.20755175 0.20755175 0.11295038\n",
      "  0.1277719  0.24737185 0.52939546 0.42209157]\n",
      " [0.16156007 0.99999994 0.4548301  0.4548301  0.4548301  0.37738892\n",
      "  0.5300653  0.5891814  0.00793771 0.19965407]\n",
      " [0.20755175 0.4548301  1.         1.         1.         0.47099152\n",
      "  0.7585943  0.79638106 0.15515406 0.33600876]\n",
      " [0.3094829  0.46337876 0.6778307  0.6778307  0.6778307  0.5518821\n",
      "  0.6927722  0.73942804 0.13986805 0.38769734]\n",
      " [0.20755175 0.4548301  1.         1.         1.         0.47099152\n",
      "  0.7585943  0.79638106 0.15515406 0.33600876]\n",
      " [0.11295038 0.37738892 0.47099152 0.47099152 0.47099152 1.0000002\n",
      "  0.68740535 0.53704435 0.02584004 0.15731354]\n",
      " [0.20755175 0.4548301  1.         1.         1.         0.47099152\n",
      "  0.7585943  0.79638106 0.15515406 0.33600876]\n",
      " [0.11295038 0.37738892 0.47099152 0.47099152 0.47099152 1.0000002\n",
      "  0.68740535 0.53704435 0.02584004 0.15731354]\n",
      " [0.24737185 0.5891814  0.79638106 0.79638106 0.79638106 0.53704435\n",
      "  0.8413363  0.9999998  0.11561738 0.46169382]\n",
      " [0.52939546 0.00793771 0.15515406 0.15515406 0.15515406 0.02584004\n",
      "  0.07008217 0.11561738 1.         0.26549956]]\n"
     ]
    }
   ],
   "source": [
    "cosine_simil = cosine_similarity(embedding_b, embedding_c)\n",
    "print(f'Cosine Similarity between block a and block b: {cosine_simil}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Vocab C:/Users/thodo/Documents/σχολη/diplomatiki/PalmTree/pre-trained_model/palmtree/vocab\n",
      "Vocab Size:  6631\n",
      "Loading Vocab C:/Users/thodo/Documents/σχολη/diplomatiki/PalmTree/pre-trained_model/palmtree/vocab\n",
      "Vocab Size:  6631\n",
      "Loading Vocab C:/Users/thodo/Documents/σχολη/diplomatiki/PalmTree/pre-trained_model/palmtree/vocab\n",
      "Vocab Size:  6631\n",
      "Loading Vocab C:/Users/thodo/Documents/σχολη/diplomatiki/PalmTree/pre-trained_model/palmtree/vocab\n",
      "Vocab Size:  6631\n"
     ]
    }
   ],
   "source": [
    "inst_a = [\"mov rbp, rsp\"]\n",
    "inst_b = [\"add DWORD PTR [rbp-4], eax\"]\n",
    "inst_c = [\"add DWORD PTR [rbp-16], eax\"]\n",
    "inst_d = [\"pop rbp\"]\n",
    "\n",
    "suffixes = ['a', 'b', 'c', 'd']\n",
    "\n",
    "instructions = [inst_a, inst_b, inst_c, inst_d]\n",
    "\n",
    "embeddings = {suffix: embedder.encode(inst) for inst, suffix in zip(instructions, suffixes)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b', 'c', 'd']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(embeddings.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "combs = itertools.combinations(embeddings.keys(), 2)\n",
    "similarities = {f'{comb[0]}_{comb[1]}': cosine_similarity(embeddings[comb[0]], embeddings[comb[1]]) for comb in combs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a_b': array([[0.25822026]], dtype=float32),\n",
       " 'a_c': array([[0.25822026]], dtype=float32),\n",
       " 'a_d': array([[0.01792558]], dtype=float32),\n",
       " 'b_c': array([[1.0000001]], dtype=float32),\n",
       " 'b_d': array([[0.08860988]], dtype=float32),\n",
       " 'c_d': array([[0.08860988]], dtype=float32)}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('energy-prediction')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2d8ea44dacc84c32c3ffb10f5fa42b465f31145cc9ac97a8028dfa96db72aa4c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
